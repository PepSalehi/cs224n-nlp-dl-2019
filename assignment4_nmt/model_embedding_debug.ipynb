{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from vocab import *\n",
    "from model_embeddings import *\n",
    "from utils import * \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Vocab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check `Vocab` class. This ia a standard class to deal with encoding of corpus. It contains familiar methods like `words2indices` that encode sentences as a list of integers using indicies in vocabulary.\n",
    "\n",
    "It also overrides some methods like `__len__()` and `__getitem__` and other. So we may call `len` on it and use `[]` to get an index (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'vocab.json'\n",
    "vocab = Vocab.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(vocab.Vocab, vocab.VocabEntry, vocab.VocabEntry)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab), type(vocab.src), type(vocab.tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50004, 50002)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.src.id2word), len(vocab.tgt.id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50004, 50002)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we may call len directly on \n",
    "len(vocab.src), len(vocab.tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<s>', '</s>', '<unk>', 'de', 'que', 'la', 'en', 'y', 'el']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.src.id2word[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<s>', '</s>', '<unk>', 'the', 'to', 'of', 'a', 'and', 'that']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.tgt.id2word[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.src['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ModelEmbeddings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here's the question: why should we specify `padding_idx` in our `Embedding` layer? We may read in docs: *If given, pads the output with the embedding vector at padding_idx (initialized to zeros) whenever it encounters the index*. What does this mean?\n",
    "\n",
    "Let's create 2 layers: with and without `padding_idx` parameter. We may see that indeed in the first scenario (but not in the second) we have vector of all zeros as an embedding for our `padding_idx`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 2\n",
    "torch.manual_seed(42)\n",
    "embed_with_pad = nn.Embedding(num_embeddings=len(vocab.src), \n",
    "                     embedding_dim=embed_dim, \n",
    "                     padding_idx=vocab.src['<pad>'])\n",
    "embed_no_pad = nn.Embedding(num_embeddings=len(vocab.src), \n",
    "                     embedding_dim=embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"it's a true story -- every bit of this is true .\".split(), \n",
    "         \"driving ourselves .\".split(),\n",
    "         \"there's been kind of a series of epiphanies .\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 10, 3, 3, 65, 3, 48630, 4205, 3, 21832, 3, 1295],\n",
       " [3, 3, 1295],\n",
       " [3, 3, 3, 4205, 10, 13003, 4205, 3, 1295]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_int = vocab.src.words2indices(sents)\n",
    "sents_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_int_padded = pad_sents(sents=sents_int, \n",
    "                             pad_token=vocab.src['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 10, 3, 3, 65, 3, 48630, 4205, 3, 21832, 3, 1295],\n",
       " [3, 3, 1295, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3, 3, 3, 4205, 10, 13003, 4205, 3, 1295, 0, 0, 0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_int_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0431, -1.6047],\n",
       "         [-0.7581,  1.0783],\n",
       "         [-0.0431, -1.6047],\n",
       "         [-0.0431, -1.6047],\n",
       "         [-1.4364, -1.1299],\n",
       "         [-0.0431, -1.6047],\n",
       "         [ 0.3067,  0.5527],\n",
       "         [ 0.0292,  1.8709],\n",
       "         [-0.0431, -1.6047],\n",
       "         [-1.8290,  0.3548],\n",
       "         [-0.0431, -1.6047],\n",
       "         [ 2.7125, -0.1935]],\n",
       "\n",
       "        [[-0.0431, -1.6047],\n",
       "         [-0.0431, -1.6047],\n",
       "         [ 2.7125, -0.1935],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0431, -1.6047],\n",
       "         [-0.0431, -1.6047],\n",
       "         [-0.0431, -1.6047],\n",
       "         [ 0.0292,  1.8709],\n",
       "         [-0.7581,  1.0783],\n",
       "         [ 0.3018,  1.1055],\n",
       "         [ 0.0292,  1.8709],\n",
       "         [-0.0431, -1.6047],\n",
       "         [ 2.7125, -0.1935],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_with_pad(torch.LongTensor(sents_int_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5085, -1.6564],\n",
       "         [ 1.8229, -0.3589],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.7962, -3.4634],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [-0.0915, -0.0545],\n",
       "         [ 0.2374,  1.5812],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [-1.2246, -0.0556],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.0704,  1.0442]],\n",
       "\n",
       "        [[ 0.5085, -1.6564],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.0704,  1.0442],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530]],\n",
       "\n",
       "        [[ 0.5085, -1.6564],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.2374,  1.5812],\n",
       "         [ 1.8229, -0.3589],\n",
       "         [ 1.6651,  0.6543],\n",
       "         [ 0.2374,  1.5812],\n",
       "         [ 0.5085, -1.6564],\n",
       "         [ 0.0704,  1.0442],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530],\n",
       "         [-0.1748,  0.4530]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_no_pad(torch.LongTensor(sents_int_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
